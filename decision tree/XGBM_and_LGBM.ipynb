{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/venkateshblks/DataScience-practice/blob/main/decision%20tree/XGBM_and_LGBM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rd8feRsNAN0Q"
      },
      "source": [
        "# First XGBoost model for Pima Indians dataset\n",
        "from numpy import loadtxt\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfZj0gYKASj-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ae74b0-7f6a-4ab9-8d6d-4de1efff7253"
      },
      "source": [
        "# load data\n",
        "dataset = loadtxt('pima-indians-diabetes.data.csv', delimiter=\",\")\n",
        "# split data into X and y\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AltDpRc9AUqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "757a0e84-ada6-4aa0-cbf2-3c315cfe505a"
      },
      "source": [
        "# split data into train and test sets\n",
        "seed = 7\n",
        "test_size = 0.33\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "X_train\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  3.   , 102.   ,  44.   , ...,  30.8  ,   0.4  ,  26.   ],\n",
              "       [  1.   ,  77.   ,  56.   , ...,  33.3  ,   1.251,  24.   ],\n",
              "       [  9.   , 124.   ,  70.   , ...,  35.4  ,   0.282,  34.   ],\n",
              "       ...,\n",
              "       [  0.   ,  57.   ,  60.   , ...,  21.7  ,   0.735,  67.   ],\n",
              "       [  1.   , 105.   ,  58.   , ...,  24.3  ,   0.187,  21.   ],\n",
              "       [  8.   , 179.   ,  72.   , ...,  32.7  ,   0.719,  36.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uasE5oYfAWFn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "e4addb65-63fa-4cff-cf1f-4ad4c2a1d456"
      },
      "source": [
        "# fit model no training data\n",
        "model = XGBClassifier()\n",
        "model1 = XGBClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "model1.fit(X,Y)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlMNBgyzAZNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41d894a-a82a-4d3e-d953-cbf3988e9401"
      },
      "source": [
        "# make predictions for test data\n",
        "import numpy as np\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred1=model1.predict(X)\n",
        "\n",
        "print(np.mean(y_pred1==Y))\n",
        "# predictions = [round(value) for value in y_pred]\n",
        "np.mean(y_pred==y_test)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7283464566929134"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-qAVXM3AbZi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3fca331-17b8-4a41-9f41-2127ffd6014f"
      },
      "source": [
        "# evaluate predictions\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 72.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WepxshEIA5qy"
      },
      "source": [
        "***Light GBM***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_aZcd2dBAL_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX6Cf0qJBCHh"
      },
      "source": [
        "# Importing the dataset\n",
        "dataset = pd.read_csv('pima-indians-diabetes.data.csv')\n",
        "# split data into X and y\n",
        "X = dataset.iloc[:,0:8]\n",
        "Y = dataset.iloc[:,8]\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW0QEt1DBD2l"
      },
      "source": [
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.25, random_state = 0)\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tcjgTk-BFxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dbc01bd-034b-43a5-ee25-31448cc122b9"
      },
      "source": [
        "import lightgbm as lgb\n",
        "d_train = lgb.Dataset(x_train, label=y_train)\n",
        "d = lgb.Dataset(X, label=Y)\n",
        "d_train"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightgbm.basic.Dataset at 0x7b9e88a8e800>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEa8q77rBRFr"
      },
      "source": [
        "params = {}\n",
        "params['learning_rate'] = 0.003\n",
        "params['boosting_type'] = 'gbdt'\n",
        "params['objective'] = 'binary'\n",
        "params['metric'] = 'binary_logloss'\n",
        "params['sub_feature'] = 0.5\n",
        "params['num_leaves'] = 10\n",
        "params['min_data'] = 50\n",
        "params['max_depth'] = 10"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ssLa99wBh_r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa96905f-5847-48fb-96bd-7b613d4e167e"
      },
      "source": [
        "clf = lgb.train(params, d_train, 100)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 206, number of negative: 369\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 638\n",
            "[LightGBM] [Info] Number of data points in the train set: 575, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.358261 -> initscore=-0.582920\n",
            "[LightGBM] [Info] Start training from score -0.582920\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf1 = lgb.train(params, d, 500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJYdai6V78CQ",
        "outputId": "6c890cc4-2b1c-45cb-d93e-9571bf8f2516"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 267, number of negative: 500\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000042 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 764\n",
            "[LightGBM] [Info] Number of data points in the train set: 767, number of used features: 8\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.348110 -> initscore=-0.627359\n",
            "[LightGBM] [Info] Start training from score -0.627359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred1=clf1.predict(X)\n",
        "predictions1 = [round(value) for value in y_pred1]\n",
        "pd.DataFrame(predictions1).value_counts()\n",
        "accuracy_score(Y, predictions1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G0Dl-Oo8KSL",
        "outputId": "dda41eeb-4b3e-4ec0-cece-6573e8e23a55"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.788787483702738"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYYGYM9XBmlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "435f0570-d805-47c4-9253-0f7bb3f58549"
      },
      "source": [
        "#Prediction\n",
        "y_pred=clf.predict(x_test)\n",
        "y_pred"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.43812292, 0.35214659, 0.44924207, 0.38766077, 0.32511792,\n",
              "       0.35233603, 0.4403519 , 0.29722223, 0.33129174, 0.31549203,\n",
              "       0.27658251, 0.35936362, 0.3195423 , 0.40663205, 0.30832361,\n",
              "       0.28649455, 0.36159717, 0.4389358 , 0.43481024, 0.35382879,\n",
              "       0.29938769, 0.37007244, 0.34072565, 0.29007051, 0.35709233,\n",
              "       0.42881573, 0.29916757, 0.39210845, 0.29198777, 0.30560728,\n",
              "       0.44398461, 0.31467065, 0.36158065, 0.43044679, 0.3742303 ,\n",
              "       0.35951053, 0.29494193, 0.33596039, 0.35488395, 0.42125883,\n",
              "       0.28649229, 0.41277426, 0.33136734, 0.3329726 , 0.34646583,\n",
              "       0.36331863, 0.34214009, 0.36019483, 0.35615555, 0.37582623,\n",
              "       0.40229468, 0.38095607, 0.33916929, 0.35815294, 0.34175651,\n",
              "       0.37154327, 0.40367155, 0.34584715, 0.34533912, 0.31998332,\n",
              "       0.40736911, 0.31406285, 0.36822606, 0.40072582, 0.3422226 ,\n",
              "       0.42699516, 0.36988567, 0.30158275, 0.34708962, 0.40855636,\n",
              "       0.32309459, 0.4216275 , 0.36543678, 0.31790536, 0.45176204,\n",
              "       0.35167509, 0.37147621, 0.28822893, 0.33632082, 0.35228848,\n",
              "       0.39378739, 0.33612408, 0.37778189, 0.29848025, 0.30542126,\n",
              "       0.36616019, 0.37227102, 0.35350673, 0.41182854, 0.31341126,\n",
              "       0.39620295, 0.29030674, 0.41568168, 0.29180241, 0.39726507,\n",
              "       0.29480114, 0.290706  , 0.29413565, 0.37530304, 0.30207711,\n",
              "       0.30658955, 0.31741054, 0.43134001, 0.33720155, 0.29294145,\n",
              "       0.34571245, 0.37520794, 0.31941443, 0.40288377, 0.28869214,\n",
              "       0.43530688, 0.43258854, 0.32807297, 0.37808412, 0.31444283,\n",
              "       0.3386271 , 0.37034422, 0.46151788, 0.38678165, 0.3109166 ,\n",
              "       0.34069444, 0.38956398, 0.37663828, 0.37461025, 0.37059186,\n",
              "       0.40167313, 0.36483266, 0.38664292, 0.30119386, 0.30671887,\n",
              "       0.40998929, 0.28671988, 0.38928028, 0.3532655 , 0.34707992,\n",
              "       0.32694245, 0.35227868, 0.32146263, 0.33224563, 0.31344046,\n",
              "       0.41826254, 0.3780354 , 0.29837062, 0.33881284, 0.33938099,\n",
              "       0.35205918, 0.45479457, 0.33751695, 0.39559062, 0.36943216,\n",
              "       0.31554578, 0.4097452 , 0.32205083, 0.28839833, 0.37956871,\n",
              "       0.28167801, 0.39496374, 0.29280007, 0.39030467, 0.33962003,\n",
              "       0.3228279 , 0.38673549, 0.29371078, 0.35996831, 0.32680927,\n",
              "       0.35073676, 0.39615563, 0.33121266, 0.28301632, 0.322201  ,\n",
              "       0.39853896, 0.338779  , 0.35563476, 0.42254498, 0.35292826,\n",
              "       0.33409744, 0.37210231, 0.3346733 , 0.33184594, 0.30930802,\n",
              "       0.3678242 , 0.36471526, 0.35087956, 0.3587322 , 0.32576338,\n",
              "       0.36016365, 0.3001719 , 0.28746434, 0.32678935, 0.31092438,\n",
              "       0.36565686, 0.37422131])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TCcf6cqDIqh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b99ccc0-861c-48f4-9bb3-bd2f3d4fabad"
      },
      "source": [
        "predictions = [round(value) for value in y_pred]\n",
        "pd.DataFrame(predictions).value_counts()\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    192\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8JXv7WNC2zn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863b008e-4728-479a-b54c-c80b6d91bc48"
      },
      "source": [
        "accuracy = accuracy_score(y_test, predictions)\n",
        "y_test\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "661    1\n",
              "122    0\n",
              "113    1\n",
              "14     1\n",
              "529    0\n",
              "      ..\n",
              "366    0\n",
              "301    0\n",
              "382    0\n",
              "140    0\n",
              "463    0\n",
              "Name: 1, Length: 192, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XdXO7gVCol-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ab95e7-84cc-4bfa-af2c-d3b8fcb5ec12"
      },
      "source": [
        "accuracy"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6822916666666666"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_ZCw6_iCqK6"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}